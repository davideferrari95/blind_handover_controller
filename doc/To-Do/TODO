ROS2 - Package Conversion:

    ✔ Created a ROS2 example package. @done(24-01-26 13:01)
    ✔ Converted `Alexa Skill` and `Alexa Conversations` to ROS2. @done(24-01-26 13:01)
    ✔ Re-Written `Node-RED` for ROS2 Integration. @done(24-01-26 13:01)
    ✔ Converted `UR Robot Drivers` to ROS2. @done(24-01-26 13:01)

Handover Controller:

    ✔ Generated Trajectories with `Polynomial Trajectory Generator` (5th Order). @done(24-01-26 13:01)
    ✔ Gripper Compensation in External Force Sensor Readings. ⇾ Teach Pendant Tool Compensation. @done(24-01-26 13:03)
    ✔ Implemented the `Admittance Controller` following a Planned Trajectory. @done(24-01-26 13:01)
    ✔ Implemented the `SSM Controller` ensuring the Safety ISO/TS 15066. @done(24-01-26 13:01)
    ✔ Implemented the `PFL Controller` ensuring the Safety ISO/TS 15066. @done(24-01-26 13:01)
    ✔ Implemented the Scaling Factor Optimization Péroblem for the `Safety Controller`. @done(24-01-26 13:01)

Load Transfer - FT Sensor:

    ✔ Study the `Force-Load Transfer` between the Robot and the Human. @done(24-02-12 16:30)
    ✔ Can we use the Force-Load Transfer to detect the Handover Success ? -> YES @done(24-02-12 16:30)
    ✔ Find a Robust strategy to detect the Handover Success. -> Neural Network @doing(24-02-12 16:30) @done(24-02-16 16:47)

    ✔ Little User-Study to find the Force-Load Transfer: @done(24-02-16 16:47)

        ✔ Robot pass an object to the human (Different Objects / Weights / Sizes / Positions). @done(24-02-16 16:47)
        ✔ Get the Force-Load Transfer Curve between the Robot and the Human. @done(24-02-16 16:47)
        ✔ Create a `Force-Load Transfer` Model with PyTorch. @done(24-02-16 16:47)
        ✔ Test the Model with different Objects / Weights / Sizes / Positions. @done(24-02-16 16:47)

    ✔ `Neural Network` to detect the Handover Success: @done(24-02-16 16:47)

        ✔ Write a `Force-Load Transfer` Model with PyTorch. @done(24-02-12 16:31)
        ✔ Write a Training Network script. @done(24-02-12 16:31)
        ✔ Write a Usage Network ROS2 Node. @done(24-02-12 16:32)
        ✔ Use the `Force-Load Transfer` Model to detect the Handover Release. @done(24-02-16 16:47)

Sensing and Communication:

    ✘ Implement the `6IMPOSE` Object Recognition. @cancelled(24-02-16 17:03)
    ✔ Implement the `Alexa Conversations` or `Gesture Recognition` for the Handover Request. @done(24-02-21 12:26)
    ✔ Implement the Handover Procedure with the `Automatic Success Detection` and `Release` of the Object. @done(24-02-16 17:03)

Comparative Handover:

    ✔ Create a `Standard Hanvoder` node without the `Admittance Controller` and the `Force-Load Transfer` Network. @done(24-02-19 14:09)
    ✔ Using the same `Handover Controller` Algorithm, with `external_force = 0` in `compute_admittance_velocity` Function. @done(24-02-19 14:09)
    ✔ Use a `Force-Load Transfer` Threshold to detect the Handover Success (Z -> 10N). @done(24-02-19 14:09)

`------------------------------------------------------------------------------------------------------------------------------------------------------`


Force-Load Transfer User Study - Experiment Details:

    Task Description:

        ✔ Robot must pass an object to the human (Different Objects / Weights / Sizes / Positions). @done(24-02-12 16:33)
        ✔ Human must take the object from the robot (Sometimes head-on, other times from behind). @done(24-02-12 16:33)
        ✔ Human must communicate when he has the object -> Robot must release the object (Button Pressure). @done(24-02-12 16:33)

        ✔ Different Objects with Different Weights and Sizes. @done(24-02-12 16:33)
        ✔ Dataset Creation without Implementing Safety (Always PFL) or Communication. @done(24-02-12 16:33)
        ✔ Pick the Object from an Hardcoded Position and go to an Handover Hardcoded Position. @done(24-02-12 16:33)
        ✔ Start Data Collection when Robot Pick the Object until Release. @done(24-02-12 16:33)

    ✘ Vice-versa Experiment ?: @cancelled(24-01-30 15:19)

        ✘ Human must pass an object to the robot. @cancelled(24-01-30 15:19)
        ✘ Robot must take the object from the human hand -> Human must release the object. @cancelled(24-01-30 15:19)
        ✘ More simple to implement, no neural network needed, only perception. @cancelled(24-01-30 15:19)

    Data Collection:

        ✔ Force-Load Transfer Curve -> FT Sensor Readings. @done(24-02-12 16:33)
        ✔ Release Time -> Synchronized with the FT Sensor Readings. @done(24-02-12 16:33)
        ✔ Velocity of the Robot ? (Handover occurs when the velocity is ~ zero). @done(24-02-12 16:33)
        ✔ Position of the Robot ? (Handover occurs when the position is ~ handover goal). @done(24-02-12 16:33)

    NN Training:

        ✔ Create a `Force-Load Transfer` Model with PyTorch. @done(24-02-12 16:32)
        ✔ Test the Model with different Objects / Weights / Sizes / Positions. @done(24-02-12 16:32)
        ✔ Output: Do Nothing / Release Object. @done(24-02-12 16:32)

        ✔ Loss Function: Binary Cross Entropy. @done(24-02-12 16:32)
        ✔ Optimizer: Adam. @done(24-02-16 17:01)

    Robust Handover:

        ✔ Collect some data where the robot takes some hits -> robust network @done(24-02-21 17:44)
        ✔ Add the new data to the training set and re-train the network @done(24-02-21 17:44)
        ✔ Use longer sequences to train the network (= 500 samples -> 0.5 seconds) @done(24-02-21 17:44)

`------------------------------------------------------------------------------------------------------------------------------------------------------`


Future Implementations:

    Handover "On Flight":

        ✔ Handover occurs while robot is moving @done(24-02-12 16:33)

    Hand / Object Tracking:

        ✘ Implement the `6IMPOSE` Object Recognition. @cancelled(24-02-28 12:11)
        ☐ Implement Object and Hand Recognition.

    Personal Safety:

        - Comparative experiment ? with *"ISO Safety"* vs *"Personal Safety"*.
        - Training task with ISO, communication and possible interactions.

        - Define How to Change Robot Behavior in according to the User Requests.

        - Define Risk Indicators:

            - Contact risk between *human head / body* and robot is different from *human hands / arms* and robot (ISO/TS 15066 - Appendix A.2 - 29 Body Areas / 12 Body Regions).
            - If Risk Indicator is too high ⇾ Slow Down.
            - NB: Biomechanical limits (max pressure and force) in ISO/TS 15066 are based on conservative estimation and scientific research on pain sensation.

        - Experiment:

            - Robot must fill some small boxes with objects (e.g. screws / pen drives etc.).
            - User must apply a label on each box.
            - User can ask robot to *Slow Down* / *Stop* / *Move Further* / *Hurry Up*.
            - Goal for the user is to finish the task as fast as possible.

        - Collect data about the interaction:

            - Execution Time
            - Experience in Robotics
            - Trust / Confidence in the Robot / Application / Task
            - User Satisfaction / Stress / Fear / Anxiety / Frustration

        - Idea:

            - Graph with User Experience (trust / confidence) vs Robot Behavior (speed / acceleration) in relation with ISO.
            - How much the velocity / distance is further from the ISO standard.
            - How much the fear / anxiety / frustration is higher / lower.
            - Coward approach ⇾ ISO makes fear ⇾ Slow down the Robot.
